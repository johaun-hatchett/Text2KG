{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config: `gpt-3.5-turbo`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OpenAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import logging\n",
    "\n",
    "openai.organization = 'org-ZSjLwLfwPKSKiv1oL1veHDLb'\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "logging.basicConfig(filename='responses.log', \n",
    "                    filemode='w', \n",
    "                    level=logging.INFO, \n",
    "                    format='%(levelname)s:%(asctime)s %(message)s', \n",
    "                    datefmt='%m-%d-%Y %H:%M:%S')\n",
    "\n",
    "# GPT prompt-response wrapper\n",
    "def GPT(messages: list) -> str:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", \n",
    "        temperature=0.3,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "    logging.info(messages)\n",
    "    logging.info(reply)\n",
    "\n",
    "    return reply"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Knowledge graph construction**\n",
    "\n",
    "Prompt GPT-3.5 to extract keywords and triplets from passage sequentially. The format of the output varies, so there are a few exception catches:\n",
    "\n",
    "1. The output is a markdown-formatted JSON\n",
    "2. The output is JSON as-is\n",
    "3. The output is an unformatted list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_knowledge(passage: str) -> tuple:\n",
    "    \"\"\"Extract keywords and triplets from passage.\"\"\"\n",
    "    context = (f'This is an information extraction task; only perform the assigned tasks'\n",
    "               f' and adhere to the given formatting. Suppress all other outputs.'\n",
    "               f' Use the following passage as context: {passage}')\n",
    "    \n",
    "    task1 = (f'Extract the named entities from the passage. The output should be'\n",
    "             f' a JSON-formatted list of key terms, ordered such that the most important'\n",
    "             f' term is first, and the least important term is last. Example: [\"atom\", \"proton\", ...]')\n",
    "    \n",
    "    task2 = (f'Using these terms and the passage, generate knowledge graph triplets.'\n",
    "             f' Output should be a JSON-formatted list of strings of the form:' \n",
    "             f' [\"subject|relation|object\", \"subject|relation|object\", ...].')\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": context},\n",
    "        {\"role\": \"user\", \"content\": task1}\n",
    "    ]\n",
    "\n",
    "    response = GPT(messages)\n",
    "    \n",
    "    try:\n",
    "        # remove markdown formatting\n",
    "        json_str = re.sub(r'^```[a-z]+\\n(.+?)\\n```$', r'\\1', response, flags=re.DOTALL)\n",
    "        keywords = json.loads(json_str)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        try:\n",
    "            keywords = json.loads(response)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": context},\n",
    "        {\"role\": \"user\", \"content\": task1},\n",
    "        {\"role\": \"assistant\", \"content\": response},\n",
    "        {\"role\": \"user\", \"content\": task2}\n",
    "    ]\n",
    "\n",
    "    response = GPT(messages)\n",
    "    \n",
    "    try:\n",
    "        # remove markdown formatting\n",
    "        json_str = re.sub(r'^```[a-z]+\\n(.+?)\\n```$', r'\\1', response, flags=re.DOTALL)\n",
    "        triplets = json.loads(json_str)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        try:\n",
    "            triplets = json.loads(response)\n",
    "        except:\n",
    "            try:\n",
    "                triplets = [item.strip(',') for item in response.splitlines() if item]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return keywords, triplets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End-to-End Process**\n",
    "\n",
    "Input:\n",
    "- list of Wikipedia pages\n",
    "\n",
    "Output:\n",
    "- JSON file containing the following hierarchy: `corpus_index/page_data/sections/information`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "import csv\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "class OS_textbook():\n",
    "    def __init__(self, filepath: str):\n",
    "        self.data = pd.read_csv(filepath)\n",
    "\n",
    "class OS_bio_2e(OS_textbook):\n",
    "    filepath = \"data/original/sentences_Biology_2e_parsed.csv\"\n",
    "    \n",
    "    def __init__(self, chapter: int, section: int):\n",
    "        super().__init__(self.filepath)\n",
    "        \n",
    "        self.chapter_num = chapter\n",
    "        self.section_num = section\n",
    "\n",
    "        self.text = self.extract_section_text()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"OS_bio_2e(chapter={self.chapter_num}, section={self.section_num})\"\n",
    "    \n",
    "    def extract_section_text(self):\n",
    "        ch = self.data[\"chapter\"] == self.chapter_num\n",
    "        sec = self.data[\"section\"] == self.section_num\n",
    "        \n",
    "        section_data = self.data[ch & sec]\n",
    "        section_text = list(section_data.sentence.values)\n",
    "\n",
    "        return section_text\n",
    "    \n",
    "    def generate_knowledge_graph(self, filepath):\n",
    "        \n",
    "        kw_filename = f\"bio_ch{self.chapter_num}_s{self.section_num}_keywords.csv\"\n",
    "        trip_filename = f\"bio_ch{self.chapter_num}_s{self.section_num}_triplets.csv\"\n",
    "\n",
    "        kw_filepath = osp.join(filepath, kw_filename)\n",
    "        trip_filepath = osp.join(filepath, trip_filename)\n",
    "        \n",
    "        with open(kw_filepath, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"keywords\", \"sentence\"])\n",
    "\n",
    "        with open(trip_filepath, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"subject\", \"relation\", \"object\", \"sentence\"])\n",
    "\n",
    "        for sentence in tqdm(self.text):\n",
    "\n",
    "            try:\n",
    "                keywords, triplets = extract_knowledge(sentence)\n",
    "                row = [keywords, sentence]\n",
    "                \n",
    "                with open(kw_filepath, 'a') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow(row)\n",
    "\n",
    "                for triplet in triplets:\n",
    "                    s,r,o = triplet.split('|')\n",
    "                    row = [s, r, o, sentence]\n",
    "\n",
    "                    with open(trip_filepath, 'a') as f:\n",
    "                        writer = csv.writer(f)\n",
    "                        writer.writerow(row)\n",
    "            except:\n",
    "                logging.info(f\"Error encountered. Sentence: {sentence}\")\n",
    "            else:\n",
    "                logging.info(f\"Extracted knowledge. Sentence: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ch4():\n",
    "    ch4 = [OS_bio_2e(chapter=4, section=num) for num in range(2,8)]\n",
    "    \n",
    "    for section in ch4:\n",
    "        section.generate_knowledge_graph(\"data/pre-processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [pd.read_csv(f\"data/pre-processed/bio_ch4_s{section}_triplets.csv\") for section in range(2,8)]\n",
    "data = pd.concat(data, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A cell is the smallest unit of a living thing.',\n",
       "       'Whether comprised of one cell (like bacteria) or many cells (like a human), we call it an organism.',\n",
       "       'Whether comprised of one cell (like bacteria) or many cells (like a human), we call it an organism.',\n",
       "       ...,\n",
       "       'To conduct a virtual microscopy lab and review the parts of a cell, work through the steps of this interactive assignment.',\n",
       "       'To conduct a virtual microscopy lab and review the parts of a cell, work through the steps of this interactive assignment.',\n",
       "       'To conduct a virtual microscopy lab and review the parts of a cell, work through the steps of this interactive assignment.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentence in data.sentence.values:\n",
    "    quads = data[data[\"sentence\"] == sentence]\n",
    "    triplets = quads.drop([\"sentence\"], axis=1)\n",
    "    triplets_list = list(triplets.itertuples(index=False, name=None))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cell',\n",
       "  'is smallest unit of',\n",
       "  'living thing',\n",
       "  'A cell is the smallest unit of a living thing.'),\n",
       " ('organism',\n",
       "  'is called',\n",
       "  'bacteria',\n",
       "  'Whether comprised of one cell (like bacteria) or many cells (like a human), we call it an organism.')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "list(d.loc[[0, 1]].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fact_verification(triplets: list[tuple], context: str):\n",
    "    \n",
    "    triplets = '\\n'.join(triplets)\n",
    "\n",
    "    f\"{triplets}\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wikiKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
